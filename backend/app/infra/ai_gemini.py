"""
Servi√ßo de IA usando Google Gemini API

Este m√≥dulo implementa a interface IAIService usando o Google Gemini.
Fornece funcionalidades de gera√ß√£o de desafios, avalia√ß√£o de submiss√µes
e an√°lise de curr√≠culos usando IA generativa.

Funcionalidades principais:
- Gera√ß√£o de desafios personalizados por track (Frontend, Backend, Data Engineer)
- Avalia√ß√£o de submiss√µes com an√°lise qualitativa e skill assessment
- An√°lise de curr√≠culos com identifica√ß√£o de gaps e sugest√µes
- Streaming de respostas para feedback em tempo real
- Retry autom√°tico com backoff exponencial
- Tratamento robusto de erros (rate limits, timeouts, etc)

Arquitetura:
- Implementa IAIService (interface definida em domain/ports.py)
- Usa Google Generative AI SDK
- Suporta streaming para respostas longas
- Valida√ß√£o e recupera√ß√£o de JSON malformado

Configura√ß√£o:
- GEMINI_API_KEY: API key do Google Gemini (obrigat√≥ria)
- GEMINI_MODEL: Modelo a usar (default: gemini-2.5-flash)
- AI_MAX_RETRIES: N√∫mero m√°ximo de tentativas (default: 5)
- AI_TIMEOUT: Timeout por requisi√ß√£o em segundos (default: 60)
"""

import json
import time
from typing import List, Dict, Optional
from backend.app.domain.ports import IAIService
from backend.app.logging_config import get_logger

logger = get_logger(__name__)

try:
    import google.generativeai as genai
    from google.generativeai.types import HarmCategory, HarmBlockThreshold
    try:
        from google.api_core.exceptions import (
            ResourceExhausted,
            ServiceUnavailable,
            InternalServerError,
            TooManyRequests
        )
    except ImportError:
        ResourceExhausted = None
        ServiceUnavailable = None
        InternalServerError = None
        TooManyRequests = None
except ImportError:
    logger.warning(
        "google-generativeai n√£o instalado. Instale com: pip install google-generativeai")
    genai = None
    ResourceExhausted = None
    ServiceUnavailable = None
    InternalServerError = None
    TooManyRequests = None


class GeminiAI(IAIService):
    """
    Implementa√ß√£o do servi√ßo de IA usando Google Gemini.
    
    Esta classe implementa a interface IAIService usando o Google Gemini API.
    Fornece m√©todos para gerar desafios, avaliar submiss√µes e analisar curr√≠culos.
    
    Caracter√≠sticas:
    - Valida√ß√£o autom√°tica de tokens e respostas
    - Retry com backoff exponencial para erros tempor√°rios
    - Backoff mais longo para erros 503 (servi√ßo sobrecarregado)
    - Streaming de respostas para feedback em tempo real
    - Recupera√ß√£o de JSON malformado
    - Valida√ß√£o de desafios gerados
    
    Attributes:
        api_key: Chave da API do Google Gemini
        model_name: Nome do modelo (default: gemini-2.5-flash)
        max_retries: N√∫mero m√°ximo de tentativas em caso de erro (default: 5)
        timeout: Timeout em segundos para cada chamada (default: 60)
        safety_settings: Configura√ß√µes de seguran√ßa (permite conte√∫do t√©cnico)
        generation_config: Configura√ß√£o de gera√ß√£o (temperature, tokens, etc)
    """

    def __init__(
        self,
        api_key: str,
        model_name: str = "models/gemini-2.5-flash",
        max_retries: int = 5,  # Aumentado de 3 para 5
        timeout: int = 60
    ):
        """
        Inicializa o cliente Gemini.

        Args:
            api_key: API key do Google Gemini
            model_name: Modelo a usar (gemini-1.5-flash ou gemini-1.5-pro)
            max_retries: Quantas vezes retentar em caso de erro
            timeout: Timeout por request em segundos

        Raises:
            ValueError: Se API key n√£o fornecida ou SDK n√£o instalado
        """
        if not genai:
            raise ValueError(
                "SDK do Google Gemini n√£o instalado. "
                "Execute: pip install google-generativeai"
            )

        if not api_key:
            raise ValueError("GEMINI_API_KEY √© obrigat√≥ria!")

        self.api_key = api_key
        self.model_name = model_name
        self.max_retries = max_retries
        self.timeout = timeout

        # Configura o SDK
        genai.configure(api_key=api_key)

        # Configura√ß√µes de seguran√ßa (permite conte√∫do t√©cnico)
        self.safety_settings = {
            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
        }

        # Configura√ß√£o de gera√ß√£o
        self.generation_config = {
            "temperature": 0.9,  # Aumentado para for√ßar mais varia√ß√£o nas dificuldades
            "top_p": 0.95,
            "top_k": 50,
            "max_output_tokens": 8192,  # Aumentado para permitir respostas maiores
        }

        logger.info(f"GeminiAI inicializado com modelo {model_name}")

    def _detect_track(self, attributes: dict) -> str:
        """
        Detecta o track de carreira baseado no career_goal.

        Args:
            attributes: Atributos do perfil com career_goal

        Returns:
            "frontend", "backend", "data_engineer" ou "fullstack"
        """
        goal = (attributes.get("career_goal") or "").lower()

        # Keywords para Data Engineer
        de_keywords = ["data engineer", "data", "pipeline", "etl", "elt",
                       "airflow", "spark", "dbt", "analytics engineer"]
        if any(k in goal for k in de_keywords):
            return "data_engineer"

        # Keywords para Fullstack (expl√≠cito)
        fs_keywords = ["fullstack", "full-stack", "full stack"]
        if any(k in goal for k in fs_keywords):
            return "fullstack"

        # Keywords para Frontend
        fe_keywords = ["frontend", "front-end", "front", "react", "vue",
                       "angular", "ui", "ux"]
        if any(k in goal for k in fe_keywords):
            return "frontend"

        # Keywords para Backend
        be_keywords = ["backend", "back-end", "back", "api", "server",
                       "node", "python", "java", "microservice"]
        if any(k in goal for k in be_keywords):
            return "backend"

        # Default: fullstack (quando n√£o identifica especificamente)
        return "fullstack"

    def _build_challenge_prompt(self, profile: dict, attributes: dict, track: str) -> str:
        """
        Constr√≥i o prompt para gera√ß√£o de desafios baseado no track.

        Args:
            profile: Dados do perfil
            attributes: Skills e career_goal
            track: Track detectado

        Returns:
            Prompt formatado
        """
        tech_skills = attributes.get("tech_skills", {})
        soft_skills = attributes.get("soft_skills", {})
        career_goal = attributes.get(
            "career_goal", "Desenvolver habilidades t√©cnicas")

        # Tech Skills formatadas
        if isinstance(tech_skills, list):
            tech_skills_text = "\n".join(
                [f"  - {skill['name']}: {skill['percentage']}/100" for skill in tech_skills])
        else:
            # Formato dict (atual)
            tech_skills_text = "\n".join(
                [f"  - {skill}: {level}/100" for skill, level in tech_skills.items()])

        # Soft Skills formatadas
        if isinstance(soft_skills, dict):
            soft_skills_text = "\n".join(
                [f"  - {skill}: {level}/100" for skill, level in soft_skills.items()])
        else:
            soft_skills_text = "N√£o avaliado"

        # Prompt base com TODAS as skills
        base_prompt = f"""Voc√™ √© um AI Career Coach. Gere 3 desafios personalizados.

PERFIL DO USU√ÅRIO:
- Track: {track.upper()}
- Objetivo: {career_goal}

TECH SKILLS (use para desafios de code/organization):
{tech_skills_text or "  - Iniciante"}

SOFT SKILLS (use para desafios de daily-task):
{soft_skills_text}

"""

        # Prompts espec√≠ficos por track (simplificados)
        if track == "data_engineer":
            track_prompt = """
Gere 3 desafios de DATA ENGINEER:
- Tipos: SQL/Python (code), Pipeline (organization), Comunica√ß√£o (daily-task)
- Categorias v√°lidas: code, daily-task, organization
- Skills alvo: SQL, Python, Airflow, Spark
"""
        elif track == "frontend":
            track_prompt = """
Gere 3 desafios de FRONTEND:
- Tipos: Bugfix/Feature (code), Comunica√ß√£o (daily-task), Planejamento (organization)
- Categorias v√°lidas: code, daily-task, organization
- Skills alvo: React, Vue, JavaScript, TypeScript, CSS
"""
        elif track == "fullstack":
            track_prompt = """
Gere 3 desafios de FULLSTACK:
- OBRIGAT√ìRIO: 1 FRONTEND + 1 BACKEND + 1 qualquer
- Tipos: C√≥digo (code), Planejamento (organization), Comunica√ß√£o (daily-task)
- Categorias v√°lidas: code, daily-task, organization
- Skills alvo: React, Python, JavaScript, FastAPI, SQL
"""
        else:  # backend
            track_prompt = """
Gere 3 desafios de BACKEND:
- Tipos: API/Bugfix (code), Performance (organization), Comunica√ß√£o (daily-task)
- Categorias v√°lidas: code, daily-task, organization
- Skills alvo: Python, Node.js, FastAPI, SQL
"""

        json_schema = """
FORMATO JSON (retorne APENAS o JSON, sem texto extra):

ESTRUTURA DE CADA DESAFIO:
{
  "title": "T√≠tulo do desafio",
  "description": {
    "text": "Descri√ß√£o conversacional (chefe pedindo) 2-3 linhas",
    "type": "codigo|texto_livre|planejamento",
    "language": "python|javascript|sql|markdown",
    "eval_criteria": ["crit√©rio1", "crit√©rio2", "crit√©rio3"],
    "target_skill": "Skill principal do perfil",
    "affected_skills": ["Skill1", "Skill2", "Skill3"],
    "hints": ["dica √∫til 1", "dica √∫til 2"],
    "enunciado": null
  },
  "difficulty": {"level": "easy|medium|hard", "time_limit": 20-90},
  "category": "code|daily-task|organization",
  "fs": {
    "files": ["caminho/arquivo1.ext", "caminho/arquivo2.ext"],
    "open": "caminho/arquivo1.ext",
    "contents": {
      "caminho/arquivo1.ext": "c√≥digo bugado ou incompleto (15-30 linhas)",
      "caminho/arquivo2.ext": "c√≥digo auxiliar relevante"
    }
  },
  "template_code": null
}

‚ö†Ô∏è IMPORTANTE: N√ÉO confunda "description.type" com "category"!
- description.type: tipo de ENUNCIADO (codigo|texto_livre|planejamento) - campo interno
- category: tipo de DESAFIO (code|daily-task|organization) - campo que define a tela do frontend

REGRAS OBRIGAT√ìRIAS:
1. Retorne array com exatamente 3 desafios
2. target_skill DEVE existir nas skills do usu√°rio (skill principal)
3. affected_skills: array com 2-4 skills do perfil que o desafio avalia (DEVE incluir target_skill)
   - Para code: skills t√©cnicas relacionadas (ex: ["Python", "FastAPI", "SQL"])
   - Para daily-task: soft skills (ex: ["Comunica√ß√£o", "Empatia", "Resolu√ß√£o de Conflitos"])
   - Para organization: skills de arquitetura (ex: ["Arquitetura", "Escalabilidade", "Trade-offs"])
   - Use nomes objetivos de habilidades (substantivos)
4. eval_criteria: Array com 3-4 habilidades que ser√£o avaliadas
   - Use nomes objetivos (ex: "Python", "FastAPI", "Comunica√ß√£o", "Resolu√ß√£o de problemas")
5. ‚ö†Ô∏è TIPOS DE DESAFIOS (REGRA CR√çTICA):
   - Gere EXATAMENTE 1 desafio de cada tipo: 1 code, 1 daily-task, 1 organization
   - ‚ùå PROIBIDO: 2 code + 1 organization (falta daily-task)
   - ‚ùå PROIBIDO: 3 code (falta daily-task e organization)
   - ‚ùå PROIBIDO: 2 daily-task + 1 code (falta organization)
   - ‚úÖ OBRIGAT√ìRIO: Sempre 1 code + 1 daily-task + 1 organization
6. ‚ö†Ô∏è DIFICULDADE DOS DESAFIOS (REGRA CR√çTICA):
   - Gere exatamente 1 desafio EASY, 1 MEDIUM e 1 HARD
   - ‚ùå PROIBIDO: organization=hard, daily-task=medium, code=easy (padr√£o fixo)
   - ‚úÖ OBRIGAT√ìRIO: Varie a distribui√ß√£o a cada gera√ß√£o
   - Exemplos de distribui√ß√µes V√ÅLIDAS:
     * code=hard, daily-task=easy, organization=medium
     * organization=easy, code=medium, daily-task=hard
     * daily-task=medium, organization=easy, code=hard
     * code=easy, organization=hard, daily-task=medium
   - Se voc√™ gerar organization=hard, daily-task=medium, code=easy, a resposta ser√° REJEITADA
7. description.text: Tom conversacional (chefe falando)
8. SEMPRE adicione 2-4 hints √∫teis e pr√°ticas
9. Para type="codigo" ‚Üí category="code":
   - fs √© OBRIGAT√ìRIO (n√£o null!)
   - fs.files: 2-4 caminhos realistas
   - fs.open: arquivo principal
   - fs.contents: TODOS os arquivos com c√≥digo real (15-30 linhas)
   - C√≥digo deve ser bugado, incompleto ou precisar refatora√ß√£o
   - enunciado: null
   - template_code: null
10. Para type="texto_livre" ‚Üí category="daily-task":
   - fs: null
   - enunciado: OBRIGAT√ìRIO - simule um e-mail/ticket realista
     Formato: {"type": "email", "de": "nome@empresa.com", "assunto": "assunto do email", "data": "2024-11-15", "corpo": "texto do email (3-5 linhas)"}
   - template_code: null
11. Para type="planejamento" ‚Üí category="organization":
   - fs: null
   - enunciado: OBRIGAT√ìRIO - requisitos estruturados
     Formato: {"type": "requisitos", "funcionais": ["req1", "req2", "req3"], "nao_funcionais": ["req1", "req2"]}
   - template_code: OBRIGAT√ìRIO - array de abas/campos do formul√°rio
     Formato: [{"id": "aba1", "label": "Nome da Aba", "fields": [{"id": "campo1", "label": "Label do Campo", "type": "dropdown|textarea|checkbox", "options": ["op1", "op2"]}]}]
     Crie 2-3 abas relevantes (ex: "Tecnologias", "Justificativa", "Trade-offs")

EXEMPLOS COMPLETOS:

// Exemplo 1: type="codigo"
{
  "title": "Corrigir Valida√ß√£o no Login",
  "description": {
    "text": "E a√≠! O endpoint de login t√° aceitando email sem @ e retornando 500. Os clientes t√£o reclamando. Pode corrigir pra retornar 400 com mensagem clara?",
    "type": "codigo",
    "language": "python",
    "eval_criteria": ["FastAPI", "Valida√ß√£o de dados", "Tratamento de erros"],
    "target_skill": "FastAPI",
    "affected_skills": ["FastAPI", "Python", "Pydantic", "APIs REST"],
    "hints": ["Use EmailStr do pydantic", "HTTPException(status_code=400)", "Adicione try-except na rota"],
    "enunciado": null
  },
  "difficulty": {"level": "easy", "time_limit": 25},
  "category": "code",
  "fs": {
    "files": ["app/auth.py", "app/models.py", "app/main.py"],
    "open": "app/auth.py",
    "contents": {
      "app/auth.py": "from fastapi import APIRouter, HTTPException\\nfrom app.models import LoginRequest\\n\\nrouter = APIRouter()\\n\\n@router.post('/login')\\ndef login(data: LoginRequest):\\n    # BUG: n√£o valida email\\n    user = find_user(data.email)\\n    if not user:\\n        raise Exception('Erro')  # BUG: status 500\\n    return {'token': create_token(user)}",
      "app/models.py": "from pydantic import BaseModel\\n\\nclass LoginRequest(BaseModel):\\n    email: str  # BUG: aceita qualquer string\\n    password: str",
      "app/main.py": "from fastapi import FastAPI\\nfrom app.auth import router\\n\\napp = FastAPI()\\napp.include_router(router)"
    }
  },
  "template_code": null
}

// Exemplo 2: type="texto_livre"
{
  "title": "Responder Cliente sobre Atraso",
  "description": {
    "text": "Oi! Temos um cliente insatisfeito com atraso na entrega. Ele enviou um email meio √°spero. Pode redigir uma resposta profissional explicando o ocorrido e oferecendo compensa√ß√£o?",
    "type": "texto_livre",
    "language": "markdown",
    "eval_criteria": ["Comunica√ß√£o escrita", "Empatia", "Resolu√ß√£o de conflitos"],
    "target_skill": "Comunica√ß√£o",
    "affected_skills": ["Comunica√ß√£o", "Empatia", "Gest√£o de crises", "Profissionalismo"],
    "hints": ["Reconhe√ßa o problema primeiro", "Explique sem fazer desculpas", "Ofere√ßa algo concreto"],
    "enunciado": {
      "type": "email",
      "de": "carlos.souza@cliente.com.br",
      "assunto": "Re: Pedido #12345 - ATRASO INACEIT√ÅVEL",
      "data": "2024-11-15",
      "corpo": "Bom dia,\\n\\nComprei o produto h√° 3 semanas e AINDA n√£o recebi. O prazo era 10 dias √∫teis. J√° entrei em contato 2 vezes e s√≥ recebi respostas autom√°ticas. Preciso de uma solu√ß√£o URGENTE ou vou cancelar e pedir reembolso.\\n\\nAguardo retorno HOJE."
    }
  },
  "difficulty": {"level": "medium", "time_limit": 30},
  "category": "daily-task",
  "fs": null,
  "template_code": null
}

// Exemplo 3: type="planejamento" (mas category="organization")
{
  "title": "Planejar Sistema de Notifica√ß√µes em Tempo Real",
  "description": {
    "text": "Fala! Vamos implementar notifica√ß√µes em tempo real no app (likes, coment√°rios, mensagens). Preciso que voc√™ planeje a arquitetura: quais tecnologias usar, como escalar, trade-offs, etc.",
    "type": "planejamento",
    "language": "markdown",
    "eval_criteria": ["Arquitetura de software", "Escalabilidade", "An√°lise de trade-offs"],
    "target_skill": "Arquitetura",
    "affected_skills": ["Arquitetura", "WebSockets", "Redis", "Escalabilidade"],
    "hints": ["Pense em WebSocket vs SSE vs Polling", "Como armazenar notifica√ß√µes n√£o lidas?", "Redis pode ajudar na performance"],
    "enunciado": {
      "type": "requisitos",
      "funcionais": [
        "Notificar usu√°rio sobre novos likes, coment√°rios e mensagens",
        "Usu√°rio deve ver badge com n√∫mero de notifica√ß√µes n√£o lidas",
        "Hist√≥rico de notifica√ß√µes dos √∫ltimos 30 dias",
        "Marcar notifica√ß√£o como lida"
      ],
      "nao_funcionais": [
        "Suportar 10 mil usu√°rios simult√¢neos",
        "Lat√™ncia m√°xima de 2 segundos",
        "Disponibilidade de 99.9%"
      ]
    }
  },
  "difficulty": {"level": "hard", "time_limit": 60},
  "category": "organization",
  "fs": null,
  "template_code": [
    {
      "id": "tecnologias",
      "label": "Tecnologias Principais",
      "fields": [
        {"id": "protocolo", "label": "Protocolo de Comunica√ß√£o", "type": "dropdown", "options": ["WebSocket", "Server-Sent Events (SSE)", "Long Polling", "Firebase Cloud Messaging"]},
        {"id": "message_broker", "label": "Message Broker", "type": "dropdown", "options": ["Redis Pub/Sub", "RabbitMQ", "Apache Kafka", "N√£o usar"]},
        {"id": "armazenamento", "label": "Armazenamento de Notifica√ß√µes", "type": "dropdown", "options": ["PostgreSQL", "MongoDB", "Redis", "DynamoDB"]}
      ]
    },
    {
      "id": "justificativa",
      "label": "Justificativa T√©cnica",
      "fields": [
        {"id": "porque_protocolo", "label": "Por que escolheu esse protocolo?", "type": "textarea"},
        {"id": "porque_broker", "label": "Por que escolheu esse message broker?", "type": "textarea"},
        {"id": "porque_storage", "label": "Por que escolheu esse armazenamento?", "type": "textarea"}
      ]
    },
    {
      "id": "tradeoffs",
      "label": "Trade-offs e Desafios",
      "fields": [
        {"id": "limitacoes", "label": "Quais as principais limita√ß√µes da sua solu√ß√£o?", "type": "textarea"},
        {"id": "alternativas", "label": "Que alternativas voc√™ considerou?", "type": "textarea"},
        {"id": "custos", "label": "Como seria o custo/complexidade?", "type": "dropdown", "options": ["Baixo", "M√©dio", "Alto"]}
      ]
    }
  ]
}
"""

        return base_prompt + track_prompt + json_schema

    def _build_evaluation_prompt(self, challenge: dict, submission: dict, track: str) -> str:
        """
        Constr√≥i o prompt para avalia√ß√£o de submiss√£o.

        Args:
            challenge: Dados do desafio
            submission: C√≥digo/texto submetido
            track: Track do usu√°rio

        Returns:
            Prompt formatado
        """
        ch_desc = challenge.get("description", {})
        ch_diff = challenge.get("difficulty", {})

        # Extrai dados da submiss√£o de acordo com o tipo
        submission_type = (submission.get("type") or "codigo").lower()
        submitted_content = ""
        template_code = challenge.get("template_code") or []

        if submission_type in {"codigo", "code"}:
            # Para c√≥digo: extrai arquivos
            files = submission.get("files", {})
            if files:
                submitted_content = "\n\n".join([
                    f"// {filename}\n{content}"
                    for filename, content in files.items()
                ])
            else:
                submitted_content = submission.get("content", "")

        elif submission_type in {"texto_livre", "daily_task", "texto", "text"}:
            # Para texto livre: extrai o conte√∫do textual
            submitted_content = submission.get("content", "")

        elif submission_type in {"organization", "planejamento", "planning"}:
            # Para planejamento/organization: agrupa respostas por se√ß√£o com r√≥tulos
            sections_data = submission.get("sections") or submission.get("form_data") or {}
            implementation_text = submission.get(
                "implementation") or submission.get("content") or ""

            if sections_data:
                field_lookup: Dict[str, Dict[str, str]] = {}
                if isinstance(template_code, list):
                    for section in template_code:
                        section_label = section.get(
                            "label") or section.get("id") or "Se√ß√£o"
                        for field in section.get("fields", []):
                            field_id = field.get("id")
                            if not field_id:
                                continue
                            field_lookup[field_id] = {
                                "section_label": section_label,
                                "field_label": field.get("label") or field_id
                            }

                grouped: Dict[str, List[tuple[str, str]]] = {}
                for field_id, answer in sections_data.items():
                    if answer is None:
                        continue
                    answer_text = answer if isinstance(
                        answer, str) else json.dumps(answer, ensure_ascii=False, indent=2)

                    info = field_lookup.get(field_id)
                    section_label = info["section_label"] if info else "Se√ß√£o Geral"
                    field_label = info["field_label"] if info else field_id

                    grouped.setdefault(section_label, []).append(
                        (field_label, answer_text))

                parts = []
                for section_label, fields in grouped.items():
                    parts.append(f"### {section_label}")
                    for field_label, answer_text in fields:
                        parts.append(f"- {field_label}: {answer_text}")
                    parts.append("")

                submitted_content = "\n".join(parts).strip()

            if implementation_text:
                impl_block = implementation_text if isinstance(
                    implementation_text, str) else json.dumps(implementation_text, ensure_ascii=False, indent=2)
                if submitted_content:
                    submitted_content = f"{submitted_content}\n\n=== PLANO DE IMPLEMENTA√á√ÉO ===\n{impl_block}"
                else:
                    submitted_content = f"=== PLANO DE IMPLEMENTA√á√ÉO ===\n{impl_block}"

            if not submitted_content:
                # Fallback se nada foi preenchido
                submitted_content = submission.get("content", "")

        # Adiciona contexto do enunciado se existir
        enunciado_context = ""
        enunciado = ch_desc.get('enunciado')
        if enunciado:
            enunciado_type = enunciado.get('type')
            if enunciado_type == 'email':
                # Para texto_livre: mostra o email/ticket original
                enunciado_context = f"""
CONTEXTO - EMAIL/TICKET ORIGINAL QUE O CANDIDATO DEVERIA RESPONDER:
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
De: {enunciado.get('de', 'N/A')}
Assunto: {enunciado.get('assunto', 'N/A')}
Data: {enunciado.get('data', 'N/A')}

{enunciado.get('corpo', '')}
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

"""
            elif enunciado_type == 'requisitos':
                # Para organization: mostra os requisitos
                funcionais = enunciado.get('funcionais', [])
                nao_funcionais = enunciado.get('nao_funcionais', [])
                enunciado_context = f"""
CONTEXTO - REQUISITOS DO PROJETO:
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
Requisitos Funcionais:
{chr(10).join('  ‚Ä¢ ' + req for req in funcionais)}

Requisitos N√£o-Funcionais:
{chr(10).join('  ‚Ä¢ ' + req for req in nao_funcionais)}
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

"""

        base_prompt = f"""Voc√™ √© um avaliador t√©cnico s√™nior especializado em {track.upper()}.

DESAFIO PROPOSTO:
T√≠tulo: {challenge.get('title')}
Descri√ß√£o: {ch_desc.get('text')}
Tipo: {ch_desc.get('type')}
Dificuldade: {ch_diff.get('level', 'medium')}
Crit√©rios de avalia√ß√£o: {', '.join(ch_desc.get('eval_criteria', []))}
{enunciado_context}
SUBMISS√ÉO DO CANDIDATO:
```{ch_desc.get('language', 'text')}
{submitted_content}
```

"""

        # Crit√©rios espec√≠ficos por track
        if track == "data_engineer":
            criteria = """
CRIT√âRIOS DE AVALIA√á√ÉO PARA DATA ENGINEER:

Para C√ìDIGO (SQL/Python):
- Corretude: resolve o problema?
- Performance: considera √≠ndices, parti√ß√µes, otimiza√ß√µes?
- Reprodutibilidade: c√≥digo pode ser executado novamente?
- Tratamento de dados: lida com nulos, duplicados, edge cases?
- Boas pr√°ticas: c√≥digo limpo, comentado, mant√≠vel?

Para PLANEJAMENTO (Pipelines/Arquitetura):
- Orquestra√ß√£o: DAGs claros, depend√™ncias bem definidas?
- Idempot√™ncia: reruns s√£o seguros?
- Monitoramento: m√©tricas, alertas, observabilidade?
- Escalabilidade: design aguenta crescimento de dados?
- Tratamento de falhas: retries, dead letter queues?

Para COMUNICA√á√ÉO:
- Clareza t√©cnica: explica bem?
- Contexto de neg√≥cio: entende impacto?
- Acionabilidade: prop√µe solu√ß√µes concretas?
"""
        elif track == "frontend":
            criteria = """
CRIT√âRIOS DE AVALIA√á√ÉO PARA FRONTEND:

Para C√ìDIGO (React/Vue/JS):
- Funcionalidade: componente funciona corretamente?
- UI/UX: interface intuitiva e responsiva?
- Performance: evita re-renders desnecess√°rios?
- Acessibilidade: semantic HTML, ARIA labels?
- Boas pr√°ticas: componentes reutiliz√°veis, c√≥digo limpo?

Para PLANEJAMENTO (Arquitetura):
- Componentiza√ß√£o: divis√£o l√≥gica de componentes?
- Estado: gerenciamento adequado (local vs global)?
- Performance: lazy loading, code splitting?
- Manutenibilidade: c√≥digo escal√°vel?

Para COMUNICA√á√ÉO:
- Clareza: explica decis√µes t√©cnicas?
- Justificativa: fundamenta escolhas de design?
"""
        else:  # backend
            criteria = """
CRIT√âRIOS DE AVALIA√á√ÉO PARA BACKEND:

Para C√ìDIGO (API/Endpoints):
- Funcionalidade: endpoint funciona corretamente?
- Valida√ß√£o: valida inputs adequadamente?
- Seguran√ßa: autentica√ß√£o, autoriza√ß√£o, sanitiza√ß√£o?
- Performance: queries otimizadas, cache apropriado?
- Boas pr√°ticas: c√≥digo limpo, tratamento de erros?

Para PLANEJAMENTO (Arquitetura):
- Design: endpoints bem estruturados?
- Escalabilidade: aguenta carga crescente?
- Manutenibilidade: c√≥digo modular e test√°vel?
- Monitoramento: logs, m√©tricas, alertas?

Para COMUNICA√á√ÉO:
- Clareza t√©cnica: explica problemas bem?
- Contexto: entende impacto em sistema?
"""

        # Extrai affected_skills do desafio para avaliar m√∫ltiplas skills
        affected_skills = (ch_desc.get("affected_skills") or [ch_desc.get("target_skill")] or [])
        affected_skills_str = ", ".join(affected_skills) if affected_skills else "skill principal"
        
        assessment_instructions = f"""
TAREFA DE AVALIA√á√ÉO:

1. Analise a submiss√£o profundamente considerando os crit√©rios acima
2. Atribua uma nota geral (0-100)
3. Avalie m√©tricas espec√≠ficas por crit√©rio
4. IMPORTANTE: Fa√ßa SKILLS ASSESSMENT (M√öLTIPLAS SKILLS):
   
   O desafio avalia estas skills: {affected_skills_str}
   
   Para CADA skill, avalie:
   
   a) skill_level_demonstrated (0-100):
      - N√ÉO √© igual √† nota geral!
      - Considere: nota + qualidade + pr√°ticas + complexidade ESPEC√çFICOS dessa skill
      - Exemplo: nota geral 85, mas Python=90 (excelente), SQL=70 (b√°sico)
   
   b) progression_intensity (-1.0 a +1.0):
      - Positivo: submiss√£o mostra dom√≠nio/evolu√ß√£o nessa skill
        * +0.9: excelente, dom√≠nio claro
        * +0.7: muito bom, boas pr√°ticas
        * +0.5: bom, competente
        * +0.3: satisfat√≥rio, funcional
        * +0.1: m√≠nimo aceit√°vel
      - Negativo: submiss√£o mostra problemas/desconhecimento
        * -0.2: falhas leves, m√°s pr√°ticas
        * -0.5: falhas significativas, desconhecimento
      
   c) reasoning (string):
      - Explique POR QU√ä essa skill espec√≠fica deve progredir/regredir
      - Seja espec√≠fico sobre o uso DESSA skill na submiss√£o
      - Mencione pontos fortes E fracos

FORMATO DE SA√çDA (JSON ESTRITO):
Retorne APENAS JSON neste formato:

{{
  "nota_geral": 85,
  "metricas": {{
    "criterio1": 90,
    "criterio2": 85,
    "criterio3": 80
  }},
  "pontos_positivos": [
    "Ponto forte 1",
    "Ponto forte 2"
  ],
  "pontos_negativos": [
    "Ponto a melhorar 1",
    "Ponto a melhorar 2"
  ],
  "sugestoes_melhoria": [
    "Sugest√£o espec√≠fica 1",
    "Sugest√£o espec√≠fica 2"
  ],
  "feedback_detalhado": "An√°lise detalhada em 2-4 linhas explicando a avalia√ß√£o geral",
  "skills_assessment": {{
    "{affected_skills[0] if affected_skills else 'SkillName1'}": {{
      "skill_level_demonstrated": 90,
      "progression_intensity": 0.8,
      "reasoning": "Excelente uso de recursos avan√ßados, c√≥digo limpo e bem estruturado"
    }},
    "{affected_skills[1] if len(affected_skills) > 1 else 'SkillName2'}": {{
      "skill_level_demonstrated": 75,
      "progression_intensity": 0.5,
      "reasoning": "Implementa√ß√£o funcional mas poderia ser mais robusta"
    }}
  }}
}}

REGRAS CR√çTICAS:
- Retorne APENAS o JSON, sem texto antes ou depois
- DEVE avaliar TODAS as skills em: {affected_skills_str}
- Cada skill tem seu pr√≥prio assessment independente
- Seja justo mas rigoroso
- Valorize boas pr√°ticas mesmo que funcione
- Penalize m√°s pr√°ticas mesmo que funcione
- skill_level_demonstrated de cada skill deve ser calculado individualmente
"""

        return base_prompt + criteria + assessment_instructions

    def _call_gemini(self, prompt: str, response_mime_type: str = "application/json") -> str:
        """
        Chama a API do Gemini com retry logic.

        Args:
            prompt: Prompt a enviar
            response_mime_type: Tipo de resposta esperada

        Returns:
            Resposta da API como string

        Raises:
            Exception: Se falhar ap√≥s todas as tentativas
        """
        model = genai.GenerativeModel(
            model_name=self.model_name,
            safety_settings=self.safety_settings,
            generation_config={
                **self.generation_config,
                "response_mime_type": response_mime_type
            }
        )

        last_error = None
        for attempt in range(1, self.max_retries + 1):
            try:
                logger.info(
                    f"Chamando Gemini (tentativa {attempt}/{self.max_retries})")

                response = model.generate_content(
                    prompt,
                    request_options={
                        "timeout": self.timeout,
                        "retry": None  # desativa retry autom√°tico do SDK
                    }
                )

                # Log de uso (para monitorar custos)
                if hasattr(response, 'usage_metadata'):
                    logger.info(
                        "Gemini API call successful",
                        extra={"extra_data": {
                            "input_tokens": getattr(response.usage_metadata, 'prompt_token_count', 0),
                            "output_tokens": getattr(response.usage_metadata, 'candidates_token_count', 0),
                            "attempt": attempt
                        }}
                    )

                return response.text

            except Exception as e:
                last_error = e
                error_str = str(e)
                error_code = getattr(e, "code", None) or getattr(e, "status_code", None)
                
                # Detecta erro 503 (Service Unavailable / Model Overloaded)
                is_503 = (
                    "503" in error_str or
                    "overloaded" in error_str.lower() or
                    "service unavailable" in error_str.lower() or
                    (ServiceUnavailable is not None and isinstance(e, ServiceUnavailable)) or
                    error_code == 503
                )
                
                logger.warning(
                    f"Gemini API error (tentativa {attempt}/{self.max_retries}): {e}",
                    extra={"extra_data": {
                        "error": str(e),
                        "error_code": error_code,
                        "is_503": is_503,
                        "attempt": attempt
                    }}
                )

                # Backoff exponencial
                if attempt < self.max_retries:
                    # Para erros 503, usa backoff mais longo e com jitter
                    if is_503:
                        # Backoff mais agressivo com jitter: 15s, 20s, 30s, 40s, 40s
                        # Adiciona jitter aleat√≥rio de 0-5s para evitar "thundering herd"
                        import random
                        base_wait = [15, 20, 30, 40, 40][min(attempt - 1, 4)]
                        jitter = random.uniform(0, 5)
                        wait_time = base_wait + jitter
                    else:
                        # Backoff padr√£o: 2s, 4s, 8s, 16s, 30s
                        wait_time = min(2 ** attempt, 30)

                    retry_delay_seconds = None
                    # Tenta extrair retry_delay de ResourceExhausted (429) ou TooManyRequests
                    if ResourceExhausted is not None and isinstance(e, ResourceExhausted):
                        retry_delay = getattr(e, "retry_delay", None)
                        if retry_delay:
                            if hasattr(retry_delay, "total_seconds"):
                                retry_delay_seconds = retry_delay.total_seconds()
                            elif hasattr(retry_delay, "seconds"):
                                retry_delay_seconds = retry_delay.seconds
                    elif TooManyRequests is not None and isinstance(e, TooManyRequests):
                        retry_delay = getattr(e, "retry_delay", None)
                        if retry_delay:
                            if hasattr(retry_delay, "total_seconds"):
                                retry_delay_seconds = retry_delay.total_seconds()
                            elif hasattr(retry_delay, "seconds"):
                                retry_delay_seconds = retry_delay.seconds
                    
                    # Fallback: tenta extrair retry_delay diretamente do erro
                    if not retry_delay_seconds and hasattr(e, "retry_delay") and e.retry_delay:
                        retry_delay = e.retry_delay
                        if hasattr(retry_delay, "total_seconds"):
                            retry_delay_seconds = retry_delay.total_seconds()
                        elif hasattr(retry_delay, "seconds"):
                            retry_delay_seconds = retry_delay.seconds

                    if retry_delay_seconds:
                        wait_time = max(wait_time, float(retry_delay_seconds))

                    logger.info(
                        f"Aguardando {wait_time:.1f}s antes de retentar... (erro 503: {is_503})")
                    time.sleep(wait_time)

        # Se chegou aqui, falhou todas as tentativas
        error_msg = f"Falha ao chamar Gemini ap√≥s {self.max_retries} tentativas: {last_error}"
        logger.error(error_msg)
        raise Exception(error_msg)

    def _parse_json_response(self, response_text: str, fallback: Optional[dict] = None) -> dict:
        """
        Parseia resposta JSON da API com tratamento de erros e tentativas de recupera√ß√£o.

        Args:
            response_text: Texto da resposta
            fallback: Valor padr√£o se parsing falhar

        Returns:
            Dict parseado ou fallback
        """
        try:
            # Remove poss√≠veis markdown code blocks
            cleaned = response_text.strip()
            if cleaned.startswith("```json"):
                cleaned = cleaned[7:]
            if cleaned.startswith("```"):
                cleaned = cleaned[3:]
            if cleaned.endswith("```"):
                cleaned = cleaned[:-3]
            cleaned = cleaned.strip()

            return json.loads(cleaned)
        except json.JSONDecodeError as e:
            logger.warning(f"JSON inv√°lido, tentando recuperar: {e}")

            # Tenta recuperar extraindo apenas os objetos completos
            try:
                # Se for uma lista, tenta extrair objetos v√°lidos
                if cleaned.startswith("["):
                    # Encontra todos os objetos completos (come√ßam com { e terminam com })
                    import re
                    objects = []
                    depth = 0
                    current_obj = ""
                    in_string = False
                    escape_next = False

                    for char in cleaned:
                        if escape_next:
                            current_obj += char
                            escape_next = False
                            continue

                        if char == '\\':
                            escape_next = True
                            current_obj += char
                            continue

                        if char == '"':
                            in_string = not in_string

                        if not in_string:
                            if char == '{':
                                if depth == 0:
                                    current_obj = "{"
                                else:
                                    current_obj += char
                                depth += 1
                            elif char == '}':
                                depth -= 1
                                current_obj += char
                                if depth == 0 and current_obj:
                                    try:
                                        obj = json.loads(current_obj)
                                        objects.append(obj)
                                        current_obj = ""
                                    except:
                                        current_obj = ""
                            elif depth > 0:
                                current_obj += char
                        else:
                            current_obj += char

                    if objects:
                        logger.info(
                            f"Recuperados {len(objects)} objetos v√°lidos de JSON malformado")
                        return objects
            except Exception as recovery_error:
                logger.error(f"Falha ao recuperar JSON: {recovery_error}")

            logger.error(
                f"Erro ao parsear JSON: {e}\nResposta: {response_text[:200]}")
            if fallback:
                return fallback
            raise

    # ==================== M√âTODOS DA INTERFACE ====================

    def _validate_challenge(self, challenge: dict) -> bool:
        """
        Valida se um desafio tem todos os campos obrigat√≥rios.

        Args:
            challenge: Desafio a validar

        Returns:
            True se v√°lido, False caso contr√°rio
        """
        # Log do desafio completo para debug
        challenge_title = challenge.get("title", "SEM T√çTULO")
        logger.debug(f"üîç Validando desafio: '{challenge_title}'")
        logger.debug(f"   Campos presentes: {list(challenge.keys())}")
        
        required_fields = ["title", "description", "difficulty", "category"]

        # Valida campos de primeiro n√≠vel
        for field in required_fields:
            if field not in challenge:
                logger.warning(f"‚ùå DESAFIO REJEITADO: Campo '{field}' n√£o existe no desafio '{challenge_title}'")
                logger.debug(f"   Desafio completo: {challenge}")
                return False
            
            if not challenge[field]:
                logger.warning(f"‚ùå DESAFIO REJEITADO: Campo '{field}' est√° vazio no desafio '{challenge_title}'")
                logger.debug(f"   Valor de '{field}': {challenge[field]}")
                return False

        # Valida description
        description = challenge["description"]
        if not isinstance(description, dict):
            logger.warning(f"‚ùå DESAFIO REJEITADO: 'description' n√£o √© um dict (√© {type(description)}) no desafio '{challenge_title}'")
            logger.debug(f"   Valor de 'description': {description}")
            return False

        if "text" not in description:
            logger.warning(f"‚ùå DESAFIO REJEITADO: 'description.text' n√£o existe no desafio '{challenge_title}'")
            logger.debug(f"   Campos em 'description': {list(description.keys())}")
            return False
            
        if not description["text"]:
            logger.warning(f"‚ùå DESAFIO REJEITADO: 'description.text' est√° vazio no desafio '{challenge_title}'")
            return False

        # Valida difficulty
        difficulty = challenge["difficulty"]
        if not isinstance(difficulty, dict):
            logger.warning(f"‚ùå DESAFIO REJEITADO: 'difficulty' n√£o √© um dict (√© {type(difficulty)}) no desafio '{challenge_title}'")
            logger.debug(f"   Valor de 'difficulty': {difficulty}")
            return False

        if "level" not in difficulty:
            logger.warning(f"‚ùå DESAFIO REJEITADO: 'difficulty.level' n√£o existe no desafio '{challenge_title}'")
            logger.debug(f"   Campos em 'difficulty': {list(difficulty.keys())}")
            return False
            
        if not difficulty["level"]:
            logger.warning(f"‚ùå DESAFIO REJEITADO: 'difficulty.level' est√° vazio no desafio '{challenge_title}'")
            return False

        if "time_limit" not in difficulty:
            logger.warning(f"‚ùå DESAFIO REJEITADO: 'difficulty.time_limit' n√£o existe no desafio '{challenge_title}'")
            logger.debug(f"   Campos em 'difficulty': {list(difficulty.keys())}")
            return False
            
        if not difficulty["time_limit"]:
            logger.warning(f"‚ùå DESAFIO REJEITADO: 'difficulty.time_limit' est√° vazio no desafio '{challenge_title}'")
            return False

        logger.debug(f"‚úÖ Desafio '{challenge_title}' validado com sucesso")
        return True

    def _extract_partial_fields(self, json_buffer: str) -> List[dict]:
        """
        Extrai campos parciais dos desafios (title, description) durante streaming.
        
        Returns:
            Lista de dicts com campos parciais: [{index: 0, title: "...", description: "..."}]
        """
        import re
        partial_challenges = []
        
        try:
            # Tentar encontrar t√≠tulos parciais com regex
            # Procura por padr√µes como: "title": "texto aqui"
            title_pattern = r'"title"\s*:\s*"([^"]*)"'
            titles = re.findall(title_pattern, json_buffer)
            
            # Procura por descri√ß√µes parciais
            desc_pattern = r'"description"\s*:\s*\{[^}]*"text"\s*:\s*"([^"]*)"'
            descriptions = re.findall(desc_pattern, json_buffer)
            
            # Procura por categorias
            category_pattern = r'"category"\s*:\s*"([^"]*)"'
            categories = re.findall(category_pattern, json_buffer)
            
            # Combina os campos encontrados
            for i in range(max(len(titles), len(descriptions), len(categories))):
                partial = {"index": i}
                if i < len(titles):
                    partial["title"] = titles[i]
                if i < len(descriptions):
                    partial["description"] = descriptions[i]
                if i < len(categories):
                    partial["category"] = categories[i]
                
                if len(partial) > 1:  # Tem pelo menos um campo al√©m do index
                    partial_challenges.append(partial)
            
            return partial_challenges
        except Exception as e:
            logger.debug(f"Erro ao extrair campos parciais: {e}")
            return []
    
    def _extract_complete_challenges(self, json_buffer: str) -> List[dict]:
        """
        Extrai desafios completos de um JSON parcialmente recebido (streaming).

        Args:
            json_buffer: String JSON parcial ou completa

        Returns:
            Lista de desafios completos encontrados
        """
        try:
            # Limpar buffer (remover markdown se existir)
            cleaned = json_buffer.strip()
            if cleaned.startswith("```json"):
                cleaned = cleaned[7:]
            if cleaned.startswith("```"):
                cleaned = cleaned[3:]
            if cleaned.endswith("```"):
                cleaned = cleaned[:-3]
            cleaned = cleaned.strip()

            # Tenta parsear como array completo
            parsed = json.loads(cleaned)
            if isinstance(parsed, list):
                logger.info(
                    f"‚úÖ JSON completo parseado: {len(parsed)} desafios")
                return parsed
            elif isinstance(parsed, dict) and "challenges" in parsed:
                logger.info(
                    f"‚úÖ JSON completo parseado (dict): {len(parsed['challenges'])} desafios")
                return parsed["challenges"]
            return []
        except json.JSONDecodeError as e:
            # JSON incompleto, tentar extrair objetos completos
            logger.debug(
                f"‚ö†Ô∏è JSON incompleto, tentando extra√ß√£o incremental: {str(e)[:100]}")
            challenges = []

            # Estrat√©gia mais robusta: procurar por arrays parciais
            # Tenta encontrar: [ {...}, {...}, ...
            import re

            # Primeiro, tenta encontrar o in√≠cio do array
            array_start = json_buffer.find('[')
            if array_start == -1:
                return []

            # Pega tudo a partir do [
            partial_array = json_buffer[array_start:]

            # Tenta adicionar ] no final e parsear
            try:
                test_json = partial_array.rstrip() + ']'
                parsed = json.loads(test_json)
                if isinstance(parsed, list) and len(parsed) > 0:
                    logger.info(
                        f"‚úÖ Extra√ß√£o incremental: {len(parsed)} desafios parciais")
                    return parsed
            except:
                pass

            return challenges

    async def generate_challenges_streaming(self, profile: dict, attributes: dict):
        """
        Gera desafios usando Gemini streaming e yielda eventos SSE progressivamente.

        Args:
            profile: Dados do perfil
            attributes: Skills e career_goal

        Yields:
            Dicion√°rios com eventos SSE:
            - {"type": "start", "message": "..."}
            - {"type": "progress", "percent": 0-100, "message": "..."}
            - {"type": "challenge", "data": {...}, "number": 1-3}
            - {"type": "complete", "total": 3}
            - {"type": "error", "message": "..."}
        """
        try:
            track = self._detect_track(attributes)
            logger.info(f"üé¨ Iniciando gera√ß√£o streaming para track: {track}")

            yield {
                "type": "start",
                "message": f"üß† Analisando perfil {track}..."
            }

            prompt = self._build_challenge_prompt(profile, attributes, track)

            # Configurar modelo com streaming
            generation_config = self.generation_config.copy()
            generation_config["max_output_tokens"] = 16384  # Aumentado para garantir que o JSON complete
            generation_config["response_mime_type"] = "application/json"  # For√ßa a IA a retornar JSON v√°lido
            # Nota: response_mime_type for√ßa JSON mode, garantindo que a IA complete o JSON antes de parar

            model = genai.GenerativeModel(
                model_name=self.model_name,
                generation_config=generation_config,
                safety_settings=self.safety_settings
            )

            # Progresso inicial simulado (5% -> 40%) otimizado
            import asyncio
            progress_steps = [
                (5, "üß† Analisando seu perfil..."),
                (10, "üéØ Identificando skills relevantes..."),
                (15, "üìä Avaliando n√≠vel de experi√™ncia..."),
                (20, "üîç Buscando desafios compat√≠veis..."),
                (25, "üí° Personalizando conte√∫do..."),
                (30, "‚öôÔ∏è Configurando geradores..."),
                (35, "‚è≥ Preparando contexto para IA..."),
                (40, "ü§ñ Iniciando gera√ß√£o...")
            ]
            
            for percent, message in progress_steps:
                yield {
                    "type": "progress",
                    "percent": percent,
                    "message": message
                }
                await asyncio.sleep(2.0)  # 2 segundos entre updates

            # Streaming do Gemini
            response = model.generate_content(prompt, stream=True)

            buffer = ""
            challenges_sent = 0
            last_progress = 40
            chunk_count = 0
            last_extracted_length = 0  # Para detectar novo conte√∫do nos chunks
            sent_chunks = {}  # Rastreia chunks j√° enviados por desafio: {index: {title: "...", desc: "..."}}

            logger.info("üì° Aguardando chunks do Gemini...")

            import time
            start_time = time.time()

            for chunk in response:
                chunk_count += 1
                elapsed = time.time() - start_time
                
                # Verificar se o chunk tem texto antes de processar
                # finish_reason: 1 (STOP) significa que a gera√ß√£o terminou normalmente
                if not chunk.text:
                    logger.info(f"üì¶ Chunk {chunk_count} sem texto (finish_reason: {chunk.candidates[0].finish_reason if chunk.candidates else 'unknown'})")
                    continue
                    
                buffer += chunk.text
                logger.info(
                    f"üì¶ Chunk {chunk_count} (+{elapsed:.2f}s): +{len(chunk.text)} chars (total: {len(buffer)})")

                # Atualizar progresso baseado no tamanho do buffer
                # Estimativa: ~10k chars = 3 desafios completos
                estimated_progress = min(85, 40 + (len(buffer) / 10000) * 45)

                # S√≥ envia progresso se mudou significativamente (evita spam)
                if estimated_progress - last_progress >= 5:
                    yield {
                        "type": "progress",
                        "percent": int(estimated_progress),
                        "message": f"ü§ñ Gerando desafios... ({len(buffer)} caracteres)"
                    }
                    last_progress = estimated_progress

                # Extrair e enviar campos parciais (para efeito typewriter no frontend)
                if len(buffer) > last_extracted_length + 50:  # S√≥ processa se tiver conte√∫do novo significativo
                    partial_fields = self._extract_partial_fields(buffer)
                    
                    for partial in partial_fields:
                        challenge_idx = partial.get("index", 0)
                        
                        # Inicializa rastreamento deste desafio se necess√°rio
                        if challenge_idx not in sent_chunks:
                            sent_chunks[challenge_idx] = {}
                        
                        # Envia novos campos ou campos que mudaram
                        for field in ["title", "description", "category"]:
                            if field in partial:
                                current_value = partial[field]
                                last_value = sent_chunks[challenge_idx].get(field, "")
                                
                                # S√≥ envia se h√° novo conte√∫do
                                if len(current_value) > len(last_value):
                                    yield {
                                        "type": "challenge_chunk",
                                        "challenge_index": challenge_idx,
                                        "field": field,
                                        "content": current_value,
                                        "is_complete": False
                                    }
                                    sent_chunks[challenge_idx][field] = current_value
                                    logger.debug(f"üìù Chunk parcial enviado: desafio {challenge_idx}, campo {field}, {len(current_value)} chars")
                    
                    last_extracted_length = len(buffer)

                # Tentar extrair desafios completos
                current_challenges = self._extract_complete_challenges(buffer)

                # Enviar apenas novos desafios (que ainda n√£o foram enviados)
                for challenge in current_challenges[challenges_sent:]:
                    if self._validate_challenge(challenge):
                        challenges_sent += 1

                        yield {
                            "type": "challenge",
                            "data": challenge,
                            "number": challenges_sent,
                            "total": 3
                        }

                        progress_percent = 10 + (challenges_sent / 3) * 80
                        yield {
                            "type": "progress",
                            "percent": int(progress_percent),
                            "message": f"‚úÖ Desafio {challenges_sent}/3 gerado!"
                        }

                        logger.info(
                            f"‚úÖ Desafio {challenges_sent}/3 enviado: {challenge.get('title', 'sem t√≠tulo')}")

            # Final: garantir que temos todos os desafios
            final_challenges = self._extract_complete_challenges(buffer)

            # Enviar desafios que podem ter ficado faltando
            for challenge in final_challenges[challenges_sent:]:
                if self._validate_challenge(challenge):
                    challenges_sent += 1

                    yield {
                        "type": "challenge",
                        "data": challenge,
                        "number": challenges_sent,
                        "total": 3
                    }

                    logger.info(
                        f"‚úÖ Desafio final {challenges_sent}/3 enviado: {challenge.get('title', 'sem t√≠tulo')}")

            # Verificar se temos pelo menos 1 desafio
            if challenges_sent == 0:
                raise ValueError("Nenhum desafio v√°lido foi gerado")

            yield {
                "type": "complete",
                "total": challenges_sent,
                "message": f"üéâ {challenges_sent} desafio(s) gerado(s) com sucesso!"
            }

            logger.info(
                f"üéâ Gera√ß√£o streaming conclu√≠da: {challenges_sent} desafios")

        except Exception as e:
            logger.exception("‚ùå Erro na gera√ß√£o streaming de desafios")
            yield {
                "type": "error",
                "message": f"Erro ao gerar desafios: {str(e)}"
            }

    def generate_challenges(self, profile: dict, attributes: dict) -> List[dict]:
        """
        Gera desafios personalizados usando Gemini com retry autom√°tico.

        Args:
            profile: Dados do perfil
            attributes: Skills e career_goal

        Returns:
            Lista de 3 desafios personalizados
        """
        track = self._detect_track(attributes)
        logger.info(f"Gerando desafios para track: {track}")

        prompt = self._build_challenge_prompt(profile, attributes, track)

        # Tenta at√© 5 vezes para evitar padr√£o fixo
        max_attempts = 5
        for attempt in range(max_attempts):
            try:
                response_text = self._call_gemini(
                    prompt, response_mime_type="application/json")
                challenges = self._parse_json_response(response_text)

                # Valida que √© uma lista
                if not isinstance(challenges, list):
                    logger.warning(
                        "Resposta n√£o √© uma lista, tentando extrair...")
                    if isinstance(challenges, dict) and "challenges" in challenges:
                        challenges = challenges["challenges"]
                    else:
                        raise ValueError("Formato de resposta inv√°lido")

                # Valida cada desafio
                valid_challenges = []
                for i, challenge in enumerate(challenges):
                    if self._validate_challenge(challenge):
                        valid_challenges.append(challenge)
                    else:
                        logger.warning(f"Desafio {i} inv√°lido, descartando")

                # Verifica se temos pelo menos 1 desafio v√°lido
                if not valid_challenges:
                    if attempt < max_attempts - 1:
                        logger.warning(
                            f"Nenhum desafio v√°lido na tentativa {attempt + 1}, tentando novamente...")
                        continue
                    else:
                        raise ValueError(
                            "Nenhum desafio v√°lido retornado pelo Gemini ap√≥s todas as tentativas")

                # Limita a 3 desafios
                valid_challenges = valid_challenges[:3]
                
                # ‚ö†Ô∏è VALIDA√á√ÉO ANTI-PADR√ÉO FIXO
                if len(valid_challenges) == 3:
                    # Extrai dificuldades por categoria
                    difficulty_map = {}
                    for ch in valid_challenges:
                        category = ch.get("category", "")
                        difficulty = ch.get("difficulty", {}).get("level", "")
                        difficulty_map[category] = difficulty
                    
                    # Verifica se √© o padr√£o fixo proibido
                    is_fixed_pattern = (
                        difficulty_map.get("organization") == "hard" and
                        difficulty_map.get("daily-task") == "medium" and
                        difficulty_map.get("code") == "easy"
                    )
                    
                    if is_fixed_pattern:
                        logger.warning(
                            f"‚ö†Ô∏è PADR√ÉO FIXO DETECTADO (organization=hard, daily-task=medium, code=easy) "
                            f"na tentativa {attempt + 1}. Rejeitando e regenerando..."
                        )
                        if attempt < max_attempts - 1:
                            continue
                        else:
                            logger.error("‚ùå Padr√£o fixo persistiu ap√≥s todas as tentativas!")
                            # Continua mesmo assim para n√£o bloquear o usu√°rio
                    else:
                        logger.info(
                            f"‚úÖ Distribui√ß√£o de dificuldades v√°lida: {difficulty_map}"
                        )

                logger.info(
                    f"Gerados {len(valid_challenges)} desafios v√°lidos (de {len(challenges)} retornados) na tentativa {attempt + 1}")
                return valid_challenges

            except json.JSONDecodeError as e:
                if attempt < max_attempts - 1:
                    logger.warning(
                        f"JSON inv√°lido na tentativa {attempt + 1}, tentando novamente...")
                    time.sleep(1)  # Pequeno delay antes do retry
                    continue
                else:
                    logger.error(
                        f"Erro ao parsear JSON ap√≥s {max_attempts} tentativas: {e}")
                    raise
            except Exception as e:
                logger.error(
                    f"Erro ao gerar desafios na tentativa {attempt + 1}: {e}")
                if attempt < max_attempts - 1:
                    logger.warning("Tentando novamente...")
                    time.sleep(1)
                    continue
                else:
                    raise

    def evaluate_submission(self, challenge: dict, submission: dict) -> dict:
        """
        Avalia submiss√£o usando Gemini com skill assessment inteligente.

        Args:
            challenge: Dados do desafio
            submission: C√≥digo/texto submetido

        Returns:
            Dict com nota, m√©tricas, feedback e skill_assessment
        """
        # Detecta track baseado na skill target (ou usa gen√©rico)
        target_skill = (challenge.get("description")
                        or {}).get("target_skill", "")
        track = "fullstack"  # Default
        if any(s in target_skill.lower() for s in ["sql", "airflow", "spark", "dbt"]):
            track = "data_engineer"
        elif any(s in target_skill.lower() for s in ["react", "vue", "angular", "css"]):
            track = "frontend"
        elif any(s in target_skill.lower() for s in ["python", "node", "fastapi", "api"]):
            track = "backend"

        logger.info(f"Avaliando submiss√£o (track: {track})")

        prompt = self._build_evaluation_prompt(challenge, submission, track)

        try:
            response_text = self._call_gemini(
                prompt, response_mime_type="application/json")
            evaluation = self._parse_json_response(response_text)

            # Valida campos obrigat√≥rios
            required_fields = ["nota_geral", "metricas", "skill_assessment"]
            for field in required_fields:
                if field not in evaluation:
                    logger.warning(
                        f"Campo obrigat√≥rio '{field}' ausente, adicionando default")
                    if field == "nota_geral":
                        evaluation[field] = 70
                    elif field == "metricas":
                        evaluation[field] = {}
                    elif field == "skill_assessment":
                        evaluation[field] = {
                            "skill_level_demonstrated": 70,
                            "should_progress": True,
                            "progression_intensity": 0.3,
                            "reasoning": "Avalia√ß√£o autom√°tica"
                        }

            logger.info(
                f"Avalia√ß√£o completa: nota={evaluation.get('nota_geral')}")
            return evaluation

        except Exception as e:
            logger.error(f"Erro ao avaliar submiss√£o: {e}")
            raise

    def _build_resume_analysis_prompt(self, resume_content: str, career_goal: str, track: str) -> str:
        """
        Constr√≥i o prompt para an√°lise de curr√≠culo baseado na trilha do usu√°rio.

        Args:
            resume_content: Conte√∫do do curr√≠culo
            career_goal: Objetivo de carreira do usu√°rio
            track: Track detectado (frontend, backend, data_engineer, fullstack)

        Returns:
            Prompt formatado
        """
        base_prompt = f"""Voc√™ √© um recrutador t√©cnico s√™nior especializado em {track.upper()}.

PERFIL DO CANDIDATO:
- Objetivo de carreira: {career_goal}
- Trilha: {track.upper()}

CURR√çCULO SUBMETIDO:
```
{resume_content}
```

"""

        # Habilidades e requisitos espec√≠ficos por track
        if track == "data_engineer":
            track_skills = """
HABILIDADES ESPERADAS PARA DATA ENGINEER:

T√©cnicas Fundamentais:
- SQL avan√ßado (CTEs, Window Functions, Otimiza√ß√£o)
- Python para manipula√ß√£o de dados (Pandas, PySpark)
- Modelagem de dados (dimensional, normaliza√ß√£o)
- ETL/ELT pipelines

Ferramentas Comuns:
- Orquestra√ß√£o: Airflow, Dagster, Prefect
- Processing: Spark, Dask, Databricks
- Cloud: AWS (S3, Redshift, Glue), GCP (BigQuery), Azure
- Versionamento de dados: dbt, Great Expectations

Soft Skills:
- Comunica√ß√£o com stakeholders de neg√≥cio
- Documenta√ß√£o t√©cnica clara
- Colabora√ß√£o com Data Scientists e Analistas
"""
        elif track == "frontend":
            track_skills = """
HABILIDADES ESPERADAS PARA FRONTEND:

T√©cnicas Fundamentais:
- JavaScript/TypeScript moderno (ES6+)
- Frameworks: React, Vue, Angular
- HTML5 sem√¢ntico e acessibilidade (ARIA)
- CSS moderno (Flexbox, Grid, anima√ß√µes)
- Responsive Design

Ferramentas Comuns:
- Build tools: Vite, Webpack, esbuild
- State management: Redux, Zustand, Pinia
- Testing: Jest, Vitest, Testing Library
- UI frameworks: Tailwind, Material-UI, Shadcn

Soft Skills:
- Colabora√ß√£o com designers (UI/UX)
- Aten√ß√£o a detalhes visuais
- Performance e otimiza√ß√£o
"""
        elif track == "backend":
            track_skills = """
HABILIDADES ESPERADAS PARA BACKEND:

T√©cnicas Fundamentais:
- APIs RESTful e/ou GraphQL
- Autentica√ß√£o e autoriza√ß√£o (JWT, OAuth)
- Bancos de dados (SQL e NoSQL)
- Arquitetura de microservi√ßos
- Seguran√ßa (SQL Injection, XSS, CSRF)

Ferramentas Comuns:
- Frameworks: FastAPI, Express, Django, Spring
- Bancos: PostgreSQL, MongoDB, Redis
- Message brokers: RabbitMQ, Kafka
- Containeriza√ß√£o: Docker, Kubernetes
- CI/CD: GitHub Actions, GitLab CI

Soft Skills:
- Documenta√ß√£o de APIs
- Code review
- Resolu√ß√£o de problemas complexos
"""
        else:  # fullstack
            track_skills = """
HABILIDADES ESPERADAS PARA FULLSTACK:

T√©cnicas Fundamentais:
- Frontend: React/Vue + HTML/CSS/JS
- Backend: APIs (Node.js, Python, Java)
- Bancos de dados (SQL e NoSQL)
- Autentica√ß√£o e seguran√ßa
- Deploy e DevOps b√°sico

Ferramentas Comuns:
- Frontend: React, Vue, Tailwind
- Backend: FastAPI, Express, Django
- Bancos: PostgreSQL, MongoDB
- Cloud: Vercel, AWS, Heroku
- Version control: Git, GitHub

Soft Skills:
- Vis√£o hol√≠stica de produto
- Comunica√ß√£o entre front e back
- Resolu√ß√£o de problemas end-to-end
"""

        analysis_instructions = """
TAREFA DE AN√ÅLISE:

Analise o curr√≠culo profundamente considerando as habilidades esperadas para a trilha do candidato.

Avalie:
1. **Alinhamento com a trilha**: O curr√≠culo mostra experi√™ncia relevante para o objetivo?
2. **Profundidade t√©cnica**: As habilidades s√£o apenas citadas ou h√° evid√™ncias de uso (projetos, resultados)?
3. **Gaps cr√≠ticos**: Quais habilidades essenciais est√£o faltando?
4. **Pontos fortes**: O que se destaca positivamente?
5. **Oportunidades de melhoria**: Como o curr√≠culo poderia ser mais competitivo?

FORMATO DE SA√çDA (JSON ESTRITO):
Retorne APENAS JSON neste formato:

{
  "pontos_fortes": [
    "Ponto forte 1 - seja espec√≠fico e mencione exemplos do curr√≠culo",
    "Ponto forte 2",
    "Ponto forte 3"
  ],
  "gaps_tecnicos": [
    "Skill/tecnologia ausente 1 que √© importante para {track}",
    "Skill/tecnologia ausente 2",
    "Skill/tecnologia ausente 3"
  ],
  "sugestoes_melhoria": [
    "Sugest√£o espec√≠fica 1 para melhorar o curr√≠culo",
    "Sugest√£o espec√≠fica 2",
    "Sugest√£o espec√≠fica 3"
  ],
  "nota_geral": 75,
  "resumo_executivo": "An√°lise geral em 2-4 linhas sobre como o curr√≠culo se posiciona para a trilha escolhida",
  "habilidades_evidenciadas": {
    "Skill 1": 85,
    "Skill 2": 70,
    "Skill 3": 60
  },
  "proximos_passos": [
    "A√ß√£o concreta 1 que o candidato pode tomar",
    "A√ß√£o concreta 2",
    "A√ß√£o concreta 3"
  ]
}

REGRAS:
- Retorne APENAS o JSON, sem texto antes ou depois
- Seja espec√≠fico e cite exemplos do curr√≠culo
- nota_geral: 0-100 (considerando alinhamento com trilha)
- habilidades_evidenciadas: m√°ximo 5 skills com nota 0-100
- Seja construtivo mas honesto
- Foque em gaps RELEVANTES para a trilha
"""

        return base_prompt + track_skills + analysis_instructions

    def analyze_resume(self, resume_content: str, career_goal: str) -> dict:
        """
        Analisa um curr√≠culo baseado no objetivo de carreira do usu√°rio.

        Args:
            resume_content: Conte√∫do do curr√≠culo em texto
            career_goal: Objetivo de carreira (ex: "Frontend Developer")

        Returns:
            Dict com an√°lise detalhada:
            - pontos_fortes: Lista de pontos fortes
            - gaps_tecnicos: Habilidades faltantes
            - sugestoes_melhoria: Sugest√µes para melhorar
            - nota_geral: Nota de 0-100
            - resumo_executivo: Resumo da an√°lise
            - habilidades_evidenciadas: Dict com skills e n√≠veis
            - proximos_passos: A√ß√µes concretas
        """
        # Detecta track baseado no career_goal
        track = self._detect_track({"career_goal": career_goal})

        logger.info(f"Analisando curr√≠culo para track: {track}")

        prompt = self._build_resume_analysis_prompt(
            resume_content, career_goal, track)

        try:
            response_text = self._call_gemini(
                prompt, response_mime_type="application/json")
            analysis = self._parse_json_response(response_text)

            # Valida campos obrigat√≥rios
            required_fields = ["pontos_fortes", "gaps_tecnicos",
                               "sugestoes_melhoria", "nota_geral", "resumo_executivo"]
            for field in required_fields:
                if field not in analysis:
                    logger.warning(
                        f"Campo obrigat√≥rio '{field}' ausente, adicionando default")
                    if field == "pontos_fortes":
                        analysis[field] = ["An√°lise n√£o dispon√≠vel"]
                    elif field == "gaps_tecnicos":
                        analysis[field] = ["An√°lise n√£o dispon√≠vel"]
                    elif field == "sugestoes_melhoria":
                        analysis[field] = ["An√°lise n√£o dispon√≠vel"]
                    elif field == "nota_geral":
                        analysis[field] = 70
                    elif field == "resumo_executivo":
                        analysis[field] = "An√°lise em processamento"

            logger.info(
                f"An√°lise de curr√≠culo completa: nota={analysis.get('nota_geral')}")
            return analysis

        except Exception as e:
            logger.error(f"Erro ao analisar curr√≠culo: {e}")
            raise

    def _extract_partial_resume_fields(self, json_buffer: str) -> dict:
        """
        Extrai campos parciais da an√°lise de curr√≠culo durante streaming.
        
        Returns:
            Dict com campos parciais: {resumo_executivo: "...", pontos_fortes: [...], etc}
        """
        import re
        partial_fields = {}
        
        try:
            # Tenta encontrar resumo executivo
            resumo_pattern = r'"resumo_executivo"\s*:\s*"([^"]*)"'
            resumo_match = re.search(resumo_pattern, json_buffer)
            if resumo_match:
                partial_fields["resumo_executivo"] = resumo_match.group(1)
            
            # Tenta encontrar nota geral
            nota_pattern = r'"nota_geral"\s*:\s*(\d+)'
            nota_match = re.search(nota_pattern, json_buffer)
            if nota_match:
                partial_fields["nota_geral"] = int(nota_match.group(1))
            
            # Tenta encontrar arrays (pontos fortes, gaps, sugest√µes)
            # Pontos fortes
            pontos_pattern = r'"pontos_fortes"\s*:\s*\[(.*?)\]'
            pontos_match = re.search(pontos_pattern, json_buffer, re.DOTALL)
            if pontos_match:
                items_str = pontos_match.group(1)
                items = re.findall(r'"([^"]*)"', items_str)
                if items:
                    partial_fields["pontos_fortes"] = items
            
            # Gaps t√©cnicos
            gaps_pattern = r'"gaps_tecnicos"\s*:\s*\[(.*?)\]'
            gaps_match = re.search(gaps_pattern, json_buffer, re.DOTALL)
            if gaps_match:
                items_str = gaps_match.group(1)
                items = re.findall(r'"([^"]*)"', items_str)
                if items:
                    partial_fields["gaps_tecnicos"] = items
            
            # Sugest√µes de melhoria
            sugestoes_pattern = r'"sugestoes_melhoria"\s*:\s*\[(.*?)\]'
            sugestoes_match = re.search(sugestoes_pattern, json_buffer, re.DOTALL)
            if sugestoes_match:
                items_str = sugestoes_match.group(1)
                items = re.findall(r'"([^"]*)"', items_str)
                if items:
                    partial_fields["sugestoes_melhoria"] = items
            
            return partial_fields
        except Exception as e:
            logger.debug(f"Erro ao extrair campos parciais de curr√≠culo: {e}")
            return {}

    async def analyze_resume_streaming(self, resume_content: str, career_goal: str):
        """
        Analisa curr√≠culo com streaming e yielda eventos SSE progressivamente.
        
        Args:
            resume_content: Conte√∫do do curr√≠culo
            career_goal: Objetivo de carreira
            
        Yields:
            Dicion√°rios com eventos SSE:
            - {"type": "start", "message": "..."}
            - {"type": "progress", "percent": 0-100, "message": "..."}
            - {"type": "field_chunk", "field": "resumo_executivo", "content": "..."}
            - {"type": "complete", "analysis": {...}}
            - {"type": "error", "message": "..."}
        """
        try:
            track = self._detect_track({"career_goal": career_goal})
            logger.info(f"üé¨ Iniciando an√°lise streaming para track: {track}")
            
            yield {
                "type": "start",
                "message": f"üìÑ Analisando curr√≠culo para {track}..."
            }
            
            prompt = self._build_resume_analysis_prompt(
                resume_content, career_goal, track)
            
            # Configurar modelo com streaming
            generation_config = self.generation_config.copy()
            generation_config["max_output_tokens"] = 8192
            
            model = genai.GenerativeModel(
                model_name=self.model_name,
                generation_config=generation_config,
                safety_settings=self.safety_settings
            )
            
            # Progresso inicial simulado (5% ‚Üí 40%) otimizado
            import asyncio
            progress_steps = [
                (5, "üìÑ Lendo curr√≠culo..."),
                (10, "üîç Identificando habilidades..."),
                (15, "üíº Avaliando experi√™ncias..."),
                (20, "üéì Analisando forma√ß√£o..."),
                (25, "üí° Verificando projetos..."),
                (30, "üìä Comparando com mercado..."),
                (35, "üéØ Gerando sugest√µes..."),
                (40, "ü§ñ Iniciando an√°lise detalhada...")
            ]
            
            for percent, message in progress_steps:
                yield {
                    "type": "progress",
                    "percent": percent,
                    "message": message
                }
                await asyncio.sleep(2.0)  # 2 segundos entre updates
            
            # Streaming do Gemini
            response = model.generate_content(prompt, stream=True)
            
            buffer = ""
            last_progress = 40
            chunk_count = 0
            last_extracted_length = 0
            sent_fields = {}  # Rastreia campos j√° enviados
            
            logger.info("üì° Aguardando chunks do Gemini para an√°lise...")
            
            import time
            start_time = time.time()
            
            for chunk in response:
                chunk_count += 1
                elapsed = time.time() - start_time
                
                # Verificar se o chunk tem texto antes de processar
                if not chunk.text:
                    logger.info(f"üì¶ Chunk {chunk_count} sem texto (finish_reason: {chunk.candidates[0].finish_reason if chunk.candidates else 'unknown'})")
                    continue
                    
                buffer += chunk.text
                logger.info(
                    f"üì¶ Chunk {chunk_count} (+{elapsed:.2f}s): +{len(chunk.text)} chars (total: {len(buffer)})")
                
                # Atualizar progresso baseado no tamanho do buffer
                estimated_progress = min(90, 40 + (len(buffer) / 5000) * 50)
                
                if estimated_progress - last_progress >= 5:
                    yield {
                        "type": "progress",
                        "percent": int(estimated_progress),
                        "message": f"ü§ñ Analisando... ({len(buffer)} caracteres)"
                    }
                    last_progress = estimated_progress
                
                # Extrair e enviar campos parciais
                if len(buffer) > last_extracted_length + 100:
                    partial_fields = self._extract_partial_resume_fields(buffer)
                    
                    for field, content in partial_fields.items():
                        last_value = sent_fields.get(field)
                        
                        # Para strings, s√≥ envia se mudou
                        if isinstance(content, str):
                            if content and (not last_value or len(content) > len(str(last_value))):
                                yield {
                                    "type": "field_chunk",
                                    "field": field,
                                    "content": content,
                                    "is_complete": False
                                }
                                sent_fields[field] = content
                                logger.debug(f"üìù Campo parcial enviado: {field}, {len(content)} chars")
                        
                        # Para arrays, s√≥ envia se cresceu
                        elif isinstance(content, list):
                            if content and (not last_value or len(content) > len(last_value)):
                                yield {
                                    "type": "field_chunk",
                                    "field": field,
                                    "content": content,
                                    "is_complete": False
                                }
                                sent_fields[field] = content
                                logger.debug(f"üìù Campo parcial enviado: {field}, {len(content)} items")
                        
                        # Para n√∫meros, sempre envia se mudou
                        elif isinstance(content, (int, float)):
                            if content != last_value:
                                yield {
                                    "type": "field_chunk",
                                    "field": field,
                                    "content": content,
                                    "is_complete": False
                                }
                                sent_fields[field] = content
                                logger.debug(f"üìù Campo parcial enviado: {field} = {content}")
                    
                    last_extracted_length = len(buffer)
            
            # Parse final
            analysis = self._parse_json_response(buffer)
            
            # Valida campos obrigat√≥rios
            required_fields = ["pontos_fortes", "gaps_tecnicos",
                             "sugestoes_melhoria", "nota_geral", "resumo_executivo"]
            for field in required_fields:
                if field not in analysis:
                    logger.warning(f"Campo '{field}' ausente, adicionando default")
                    if field in ["pontos_fortes", "gaps_tecnicos", "sugestoes_melhoria"]:
                        analysis[field] = ["An√°lise n√£o dispon√≠vel"]
                    elif field == "nota_geral":
                        analysis[field] = 70
                    elif field == "resumo_executivo":
                        analysis[field] = "An√°lise em processamento"
            
            yield {
                "type": "complete",
                "analysis": analysis,
                "message": "üéâ An√°lise completa!"
            }
            
            logger.info(f"üéâ An√°lise streaming conclu√≠da: nota={analysis.get('nota_geral')}")
            
        except Exception as e:
            logger.exception("‚ùå Erro na an√°lise streaming de curr√≠culo")
            yield {
                "type": "error",
                "message": f"Erro ao analisar curr√≠culo: {str(e)}"
            }
